{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiYMxLj845+Vc02biCfxtD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MO230101/The-codes-for-hydrogel-study-/blob/main/RFE%EF%BC%8BSymbolic_learn_for_HSQC_ver_3_for_paper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGczvFBoI2mC"
      },
      "outputs": [],
      "source": [
        "#個々のデータをCSVで出力（採用ver.2）\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "def perform_rfe_and_evaluate_and_save(X, y, original_df, file_name_prefix):\n",
        "    \"\"\"\n",
        "    RFEを実行し、指定された特徴量数(9-12)で抽出された特徴量を個別のCSVファイルに保存し、\n",
        "    そのモデルの予測精度も評価する関数。\n",
        "\n",
        "    このバージョンでは、RFEを全データで学習し、step=0.5で、n_features_to_select=9〜12を探索する。\n",
        "    出力CSVに元のファイルのインデックスと'CA1'列を含める。\n",
        "    \"\"\"\n",
        "    # データの欠損値チェックと補完\n",
        "    if X.isnull().values.any():\n",
        "        print(f\"Warning: NaN values found in {file_name_prefix}. Imputing with the mean.\")\n",
        "        X = X.fillna(X.mean())\n",
        "\n",
        "    # --- RFEのパラメータ設定 ---\n",
        "    step = 0.5\n",
        "    min_features_to_explore = 9\n",
        "    max_features_to_explore = 12\n",
        "    actual_max_features = X.shape[1]\n",
        "\n",
        "    if actual_max_features < min_features_to_explore:\n",
        "        print(f\"Warning: {file_name_prefix} has only {actual_max_features} features, which is less than the requested minimum of {min_features_to_explore}.\")\n",
        "        return\n",
        "\n",
        "    start_feature_count = max(1, min_features_to_explore)\n",
        "    end_feature_count = min(actual_max_features, max_features_to_explore)\n",
        "\n",
        "    if start_feature_count > end_feature_count:\n",
        "        print(f\"Warning: Invalid feature range for {file_name_prefix}. Start: {start_feature_count}, End: {end_feature_count}. Skipping RFE.\")\n",
        "        return\n",
        "\n",
        "    print(f\"--- Exploring features for {file_name_prefix} ({start_feature_count} to {end_feature_count} features) with step={step} ---\")\n",
        "\n",
        "    for n_features_to_select in range(start_feature_count, end_feature_count + 1):\n",
        "        estimator = GradientBoostingClassifier(random_state=42)\n",
        "        rfe = RFE(estimator=estimator, n_features_to_select=n_features_to_select, step=step)\n",
        "\n",
        "        # RFEを全データで学習\n",
        "        rfe.fit(X, y)\n",
        "\n",
        "        # 選択された特徴量のデータフレームを作成\n",
        "        selected_features_df = pd.DataFrame(rfe.transform(X), columns=X.columns.values[rfe.support_], index=X.index)\n",
        "\n",
        "        # --- ここから評価ロジック ---\n",
        "        # RFEで選択された特徴量でモデルを再学習\n",
        "        X_selected = rfe.transform(X)\n",
        "        model = GradientBoostingClassifier(random_state=42)\n",
        "        model.fit(X_selected, y)\n",
        "\n",
        "        # 予測と評価（全データで評価するため過剰適合の可能性あり）\n",
        "        y_pred = model.predict(X_selected)\n",
        "        y_prob = model.predict_proba(X_selected)[:, 1]\n",
        "\n",
        "        accuracy = accuracy_score(y, y_pred)\n",
        "        precision = precision_score(y, y_pred, zero_division=0)\n",
        "        recall = recall_score(y, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y, y_pred, zero_division=0)\n",
        "        auc = roc_auc_score(y, y_prob)\n",
        "\n",
        "        print(f\"  N_Features: {n_features_to_select:2d} | F1-score: {f1:.4f} | AUC: {auc:.4f}\")\n",
        "\n",
        "        # --- 元のCSVの最初の2列（インデックスとCA1列）を抽出して結合 ---\n",
        "        # `original_df`にはインデックスが設定されていることを前提とする\n",
        "        # 'CA1'列をコピー\n",
        "        initial_columns = original_df[['CA1']].copy()\n",
        "\n",
        "        # 抽出された特徴量と最初の2列を結合\n",
        "        # `selected_features_df`と`initial_columns`は同じインデックスを持つため、そのまま結合可能\n",
        "        output_df = pd.concat([initial_columns, selected_features_df], axis=1)\n",
        "\n",
        "        # 出力ファイル名を生成\n",
        "        output_file_name = f\"{file_name_prefix.replace('.csv', '')}_RFE_N{n_features_to_select}_step{int(step*10)}.csv\"\n",
        "\n",
        "        # CSVファイルとして保存\n",
        "        output_df.to_csv(output_file_name) # デフォルトでインデックスが保存される\n",
        "        print(f\"    Saved features for N={n_features_to_select} to {output_file_name}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # ファイルパスの定義\n",
        "    file1_path = '****.csv'\n",
        "    file2_path = '****.csv'\n",
        "\n",
        "    # ファイル1の読み込みとRFE実行\n",
        "    print(f\"Processing {file1_path}...\")\n",
        "    try:\n",
        "        df1 = pd.read_csv(file1_path, index_col=0)\n",
        "        X1 = df1.drop(['CA1'], axis=1)\n",
        "        y1 = df1['CA1']\n",
        "\n",
        "        perform_rfe_and_evaluate_and_save(X1, y1, df1, file1_path)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: {file1_path} not found. Please ensure the file is in the correct directory.\")\n",
        "\n",
        "    # ファイル2の読み込みとRFE実行\n",
        "    print(f\"\\nProcessing {file2_path}...\")\n",
        "    try:\n",
        "        df2 = pd.read_csv(file2_path, index_col=0)\n",
        "        X2 = df2.drop(['CA1'], axis=1)\n",
        "        y2 = df2['CA1']\n",
        "\n",
        "        perform_rfe_and_evaluate_and_save(X2, y2, df2, file2_path)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: {file2_path} not found. Please ensure the file is in the correct directory.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#しきい値設定、上位3位を表示\n",
        "# The code for HSQC\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gplearn\n",
        "from gplearn.genetic import SymbolicRegressor\n",
        "from sklearn.model_selection import train_test_split, ParameterSampler\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "import random\n",
        "from gplearn.functions import make_function\n",
        "\n",
        "# ランダムシード固定\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# データ読み込み\n",
        "data = pd.read_csv('****.csv')\n",
        "if 'Unnamed: 0' in data.columns:\n",
        "    X = data.drop(['CA1', 'Unnamed: 0'], axis=1)\n",
        "else:\n",
        "    X = data.drop('CA1', axis=1)\n",
        "y = data['CA1']\n",
        "\n",
        "# データの欠損値チェックと補完\n",
        "if X.isnull().values.any():\n",
        "    print(\"Warning: NaN values found in the dataset. Imputing with the mean.\")\n",
        "    X = X.fillna(X.mean())\n",
        "\n",
        "# データ分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=random_seed, stratify=y\n",
        ")\n",
        "\n",
        "X_train_scaled_df = X_train.copy()\n",
        "X_test_scaled_df = X_test.copy()\n",
        "\n",
        "# カスタム関数定義 (NaN 対策を含む)\n",
        "def protected_square(x):\n",
        "    return np.where(np.abs(x) < 1e10, x**2, 1e10)\n",
        "\n",
        "def multiply2(x1, x2):\n",
        "    return x1 * x2\n",
        "\n",
        "def safe_divide(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-6, 1.0, x1 / x2)\n",
        "\n",
        "def multiply3(x1, x2, x3):\n",
        "    return x1 * x2 * x3\n",
        "\n",
        "def protected_exp(x):\n",
        "    return np.where(x < 100, np.exp(x), 1e10)\n",
        "\n",
        "def protected_log(x):\n",
        "    return np.where(x > 0, np.log(x), -1e10)\n",
        "\n",
        "square_function = make_function(function=protected_square, arity=1, name='square')\n",
        "multiply2_function = make_function(function=multiply2, arity=2, name='mul2')\n",
        "safe_divide_function = make_function(function=safe_divide, arity=2, name='div')\n",
        "multiply3_function = make_function(function=multiply3, arity=3, name='mul3')\n",
        "exp_function = make_function(function=protected_exp, arity=1, name='exp')\n",
        "log_function = make_function(function=protected_log, arity=1, name='log')\n",
        "\n",
        "# 改善版：関数セットと複数の候補値を含むパラメータグリッド\n",
        "function_set = ['add', 'sub', 'mul', 'abs', log_function, 'inv', 'neg',\n",
        "                square_function,\n",
        "                multiply2_function, safe_divide_function,\n",
        "                multiply3_function,\n",
        "                exp_function]\n",
        "\n",
        "param_grid = {\n",
        "    'n_features_to_select': [10, 20],  # 特徴量数を複数試す\n",
        "    'function_set': [function_set],\n",
        "    'population_size': [1000, 2000, 5000],  # 複数の候補値\n",
        "    'generations': [100, 300, 500],  # 複数の候補値\n",
        "    'tournament_size': [5, 10],  # 複数の候補値\n",
        "    'stopping_criteria': [0.05],\n",
        "    'p_crossover': [0.95],\n",
        "    'p_subtree_mutation': [0.01],\n",
        "    'p_hoist_mutation': [0.01],\n",
        "    'p_point_mutation': [0.01],\n",
        "    'max_samples': [0.9, 1.0],\n",
        "    'parsimony_coefficient': [0.01],\n",
        "}\n",
        "\n",
        "# パラメータサンプリング\n",
        "n_iter = 5 # 試行回数を増やして、より多くの組み合わせを試す\n",
        "param_sampler = ParameterSampler(param_grid, n_iter=n_iter, random_state=random_seed)\n",
        "\n",
        "all_results = []\n",
        "# 0.1から0.9まで、0.1刻みの閾値で検証する\n",
        "thresholds = np.arange(0.1, 1.0, 0.1)\n",
        "\n",
        "for i, params in enumerate(param_sampler):\n",
        "    print(f\"\\n--- Symbolic Regression Trial {i+1}/{n_iter} ---\")\n",
        "    print(f\"Parameters: {params}\")\n",
        "\n",
        "    # 特徴量選択\n",
        "    selector = SelectKBest(score_func=f_regression, k=params['n_features_to_select'])\n",
        "    X_train_sel = selector.fit_transform(X_train_scaled_df, y_train)\n",
        "    X_test_sel = selector.transform(X_test_scaled_df)\n",
        "    selected_features = X_train.columns[selector.get_support(indices=True)].tolist()\n",
        "\n",
        "    # モデル構築\n",
        "    est = SymbolicRegressor(\n",
        "        random_state=random_seed,\n",
        "        function_set=params['function_set'],\n",
        "        metric='mse',\n",
        "        population_size=params['population_size'],\n",
        "        generations=params['generations'],\n",
        "        tournament_size=params['tournament_size'],\n",
        "        stopping_criteria=params['stopping_criteria'],\n",
        "        p_crossover=params['p_crossover'],\n",
        "        p_subtree_mutation=params['p_subtree_mutation'],\n",
        "        p_hoist_mutation=params['p_hoist_mutation'],\n",
        "        p_point_mutation=params['p_point_mutation'],\n",
        "        max_samples=params['max_samples'],\n",
        "        parsimony_coefficient=params['parsimony_coefficient'],\n",
        "        n_jobs=-1,\n",
        "        feature_names=selected_features\n",
        "    )\n",
        "\n",
        "    est.fit(X_train_sel, y_train)\n",
        "    y_pred = est.predict(X_test_sel)\n",
        "\n",
        "    # 閾値の検証\n",
        "    max_f1_for_current_model = -1.0\n",
        "    best_threshold_for_current_model = None\n",
        "    best_metrics_at_threshold = {}\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        y_pred_binary = (y_pred > threshold).astype(int)\n",
        "        f1 = f1_score(y_test, y_pred_binary, zero_division=0)\n",
        "\n",
        "        if f1 > max_f1_for_current_model:\n",
        "            max_f1_for_current_model = f1\n",
        "            best_threshold_for_current_model = threshold\n",
        "            best_metrics_at_threshold = {\n",
        "                'accuracy': accuracy_score(y_test, y_pred_binary),\n",
        "                'precision': precision_score(y_test, y_pred_binary, zero_division=0),\n",
        "                'recall': recall_score(y_test, y_pred_binary, zero_division=0),\n",
        "                'f1_score': f1\n",
        "            }\n",
        "\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "    # モデルごとの結果を格納\n",
        "    all_results.append({\n",
        "        'rank_metric': max_f1_for_current_model + auc, # F1とAUCの合計でランキング\n",
        "        'f1_score': max_f1_for_current_model,\n",
        "        'auc': auc,\n",
        "        'equation': str(est._program),\n",
        "        'features': selected_features,\n",
        "        'best_threshold': best_threshold_for_current_model,\n",
        "        'metrics_at_best_threshold': best_metrics_at_threshold,\n",
        "        'hyperparameters': {\n",
        "            'n_features_to_select': params['n_features_to_select'],\n",
        "            'population_size': params['population_size'],\n",
        "            'generations': params['generations'],\n",
        "            'tournament_size': params['tournament_size'],\n",
        "            'p_crossover': params['p_crossover'],\n",
        "            'p_subtree_mutation': params['p_subtree_mutation'],\n",
        "            'p_hoist_mutation': params['p_hoist_mutation'],\n",
        "            'p_point_mutation': params['p_point_mutation']\n",
        "        }\n",
        "    })\n",
        "\n",
        "# 結果をランキング指標でソート\n",
        "all_results.sort(key=lambda x: x['rank_metric'], reverse=True)\n",
        "\n",
        "# トップ3のモデルを表示\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"--- Symbolic Regression: Top 3 Equations ---\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for rank, result in enumerate(all_results[:3], 1):\n",
        "    print(f\"\\n--- Rank {rank} Equation ---\")\n",
        "    print(f\"  Equation: {result['equation']}\")\n",
        "    print(f\"  Features: {result['features']}\")\n",
        "    print(f\"  AUC: {result['auc']:.4f}\")\n",
        "    print(f\"  Best F1-score: {result['f1_score']:.4f} (at threshold {result['best_threshold']:.1f})\")\n",
        "    print(f\"  Other Metrics (at best threshold):\")\n",
        "    print(f\"    Accuracy: {result['metrics_at_best_threshold']['accuracy']:.4f}\")\n",
        "    print(f\"    Precision: {result['metrics_at_best_threshold']['precision']:.4f}\")\n",
        "    print(f\"    Recall: {result['metrics_at_best_threshold']['recall']:.4f}\")\n",
        "    print(f\"  Hyperparameters:\")\n",
        "    for key, value in result['hyperparameters'].items():\n",
        "        print(f\"    {key}: {value}\")"
      ],
      "metadata": {
        "id": "dfT2R1sZ3dtP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}